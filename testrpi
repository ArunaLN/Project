import cv2
import tensorflow as tf
import numpy as np
import math as m
import os

pd = os.getcwd()

input_video_path = '/Users/DELL/OneDrive/à¹€à¸”à¸ªà¸à¹Œà¸—à¹‡à¸­à¸›/New folder/TestAligned1.mp4'
output_dir = '/home/raspberrypi5/mediapipe_output'

if not os.path.exists(output_dir):
    os.makedirs(output_dir)

output_video_path = os.path.join(output_dir, 'posture_output.mp4')

# Load the MoveNet model (TensorFlow Lite)
interpreter = tf.lite.Interpreter(model_path="movenet_singlepose_lightning.tflite")
interpreter.allocate_tensors()

# Define input and output tensors
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Initialize video capture
cap = cv2.VideoCapture(input_video_path)

# Get video properties for output file
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Define the codec and create VideoWriter object to save the output video
video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (640, 480))

# Define fonts and colors
font = cv2.FONT_HERSHEY_SIMPLEX
green = (127, 255, 0)
red = (50, 50, 255)
yellow = (0, 255, 255)

# Helper function to calculate distance between two points
def findDistance(x1, y1, x2, y2):
    dist = m.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)
    return dist

# Helper function to calculate angles
def findAngle(x1, y1, x2, y2):
    if y1 == 0: y1 = 1  # Prevent division by zero
    theta = m.acos((y2 - y1) * (-y1) / (m.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))
    degree = int(180 / m.pi) * theta
    return degree

# Function to process a frame through MoveNet
def process_frame(frame):
    input_data = cv2.resize(frame, (192, 192))  # Resize to fit the model input size
    input_data = np.expand_dims(input_data, axis=0)
    input_data = input_data.astype(np.float32)

    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()

    keypoints = interpreter.get_tensor(output_details[0]['index'])[0]
    return keypoints

# Main loop for video processing
good_frames = 0
bad_frames = 0

while cap.isOpened():
    success, frame = cap.read()
    if not success:
        break
    
    # Get frame dimensions
    h, w = frame.shape[:2]

    # Process frame through MoveNet model
    keypoints = process_frame(frame)

    # Extract keypoints from MoveNet output
    nose = keypoints[0]
    left_shoulder = keypoints[5]
    right_shoulder = keypoints[6]
    left_ear = keypoints[7]
    right_ear = keypoints[8]
    left_hip = keypoints[11]
    right_hip = keypoints[12]

    # Convert keypoints to pixel coordinates
    l_shldr_x, l_shldr_y = int(left_shoulder[0] * w), int(left_shoulder[1] * h)
    r_shldr_x, r_shldr_y = int(right_shoulder[0] * w), int(right_shoulder[1] * h)
    l_ear_x, l_ear_y = int(left_ear[0] * w), int(left_ear[1] * h)
    r_ear_x, r_ear_y = int(right_ear[0] * w), int(right_ear[1] * h)
    l_hip_x, l_hip_y = int(left_hip[0] * w), int(left_hip[1] * h)
    r_hip_x, r_hip_y = int(right_hip[0] * w), int(right_hip[1] * h)

    # Calculate distance between left shoulder and right shoulder
    offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)

    # Check alignment
    if offset < 100:
        cv2.putText(frame, str(int(offset)) + ' Aligned', (w - 150, 30), font, 0.9, green, 2)
    else:
        cv2.putText(frame, str(int(offset)) + ' Not Aligned', (w - 150, 30), font, 0.9, red, 2)

    # Calculate angles
    neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)
    torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)

    # Draw keypoints and lines on the frame
    cv2.circle(frame, (l_shldr_x, l_shldr_y), 7, yellow, -1)
    cv2.circle(frame, (r_shldr_x, r_shldr_y), 7, yellow, -1)
    cv2.circle(frame, (l_ear_x, l_ear_y), 7, yellow, -1)
    cv2.circle(frame, (r_ear_x, r_ear_y), 7, yellow, -1)

    cv2.line(frame, (l_shldr_x, l_shldr_y), (r_shldr_x, r_shldr_y), green, 4)

    # Display angle and posture status
    angle_text_string = 'Neck : ' + str(int(neck_inclination)) + '  Torso : ' + str(int(torso_inclination))

    if neck_inclination < 40 and torso_inclination < 10:
        good_frames += 1
        cv2.putText(frame, angle_text_string, (10, 30), font, 0.9, green, 2)
    else:
        bad_frames += 1
        cv2.putText(frame, angle_text_string, (10, 30), font, 0.9, red, 2)

    # Calculate good/bad posture time
    good_time = (1 / fps) * good_frames
    bad_time = (1 / fps) * bad_frames

    # Display good/bad posture time
    if good_time > 0:
        time_string_good = 'Good Posture Time : ' + str(round(good_time, 1)) + 's'
        cv2.putText(frame, time_string_good, (10, h - 20), font, 0.9, green, 2)
    else:
        time_string_bad = 'Bad Posture Time : ' + str(round(bad_time, 1)) + 's'
        cv2.putText(frame, time_string_bad, (10, h - 20), font, 0.9, red, 2)

    # Write the frame to the output file
    video_writer.write(frame)
    
    # Show the frame
    cv2.imshow("Posture Detection", frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources
cap.release()
video_writer.release()
cv2.destroyAllWindows()
