import cv2
import numpy as np
import time
import os
import math as m
from tflite_runtime.interpreter import Interpreter
from tflite_runtime.interpreter import load_delegate

# ---------- ฟังก์ชัน ----------
def findDistance(x1, y1, x2, y2):
    return m.sqrt((x2 - x1)**2 + (y2 - y1)**2)

def findAngle(x1, y1, x2, y2):
    if y1 == 0: y1 = 1
    theta = m.acos((y2 - y1) * (-y1) / (m.sqrt((x2 - x1)**2 + (y2 - y1)**2) * y1))
    return int(180 / m.pi * theta)

def sendWarning():
    print("WARNING: Bad posture too long!")

# ---------- เตรียม Model ----------
model_path = "pose_detection.tflite"
interpreter = Interpreter(model_path)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
input_height = input_details[0]['shape'][1]
input_width = input_details[0]['shape'][2]

# ---------- เตรียมกล้องและวิดีโอ ----------
output_dir = '/home/pi/mediapipe_output'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

output_video_path = os.path.join(output_dir, 'posture_output.mp4')
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
fps = 15
video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (640, 480))

good_frames, bad_frames = 0, 0
font = cv2.FONT_HERSHEY_SIMPLEX

print("Starting posture detection...")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    h, w = frame.shape[:2]
    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    img_resized = cv2.resize(img_rgb, (input_width, input_height))
    input_data = np.expand_dims(img_resized, axis=0).astype(np.float32)
    input_data = input_data / 255.0

    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()

    # landmark format: [x, y, z, visibility] สำหรับแต่ละจุด
    landmarks = interpreter.get_tensor(output_details[0]['index'])[0]

    if landmarks.shape[0] >= 33:
        # index ตาม MediaPipe Pose
        LEFT_SHOULDER = 11
        RIGHT_SHOULDER = 12
        LEFT_EAR = 7
        LEFT_HIP = 23

        l_shldr = landmarks[LEFT_SHOULDER]
        r_shldr = landmarks[RIGHT_SHOULDER]
        l_ear = landmarks[LEFT_EAR]
        l_hip = landmarks[LEFT_HIP]

        l_shldr_x, l_shldr_y = int(l_shldr[0] * w), int(l_shldr[1] * h)
        r_shldr_x, r_shldr_y = int(r_shldr[0] * w), int(r_shldr[1] * h)
        l_ear_x, l_ear_y = int(l_ear[0] * w), int(l_ear[1] * h)
        l_hip_x, l_hip_y = int(l_hip[0] * w), int(l_hip[1] * h)

        offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)
        neck_angle = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)
        torso_angle = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)

        if neck_angle < 40 and torso_angle < 10:
            bad_frames = 0
            good_frames += 1
            color = (0, 255, 0)
        else:
            good_frames = 0
            bad_frames += 1
            color = (0, 0, 255)

        cv2.putText(frame, f'Neck: {neck_angle}  Torso: {torso_angle}', (10, 30), font, 0.6, color, 2)
        time_good = good_frames / fps
        time_bad = bad_frames / fps

        if time_bad > 180:
            sendWarning()

        cv2.putText(frame, f'Time Good: {round(time_good,1)}s  Bad: {round(time_bad,1)}s', (10, h - 10), font, 0.6, color, 2)

    video_writer.write(frame)

cap.release()
video_writer.release()
cv2.destroyAllWindows()
